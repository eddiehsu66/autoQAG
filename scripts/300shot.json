{"query": "Num completed Tasks: 1", "answer": "Num completed Tasks: <*>"}
{"query": "Num completed Tasks: 1", "answer": "Num completed Tasks: <*>"}
{"query": "Num completed Tasks: 1", "answer": "Num completed Tasks: <*>"}
{"query": "Num completed Tasks: 1", "answer": "Num completed Tasks: <*>"}
{"query": "Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 59 seconds.  Will retry shortly ...", "answer": "Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ..."}
{"query": "Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 226 seconds.  Will retry shortly ...", "answer": "Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ..."}
{"query": "Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 135 seconds.  Will retry shortly ...", "answer": "Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds.  Will retry shortly ..."}
{"query": "We launched 1 speculations.  Sleeping 15000 milliseconds.", "answer": "We launched <*> speculations.  Sleeping <*> milliseconds."}
{"query": "We launched 1 speculations.  Sleeping 15000 milliseconds.", "answer": "We launched <*> speculations.  Sleeping <*> milliseconds."}
{"query": "We launched 1 speculations.  Sleeping 15000 milliseconds.", "answer": "We launched <*> speculations.  Sleeping <*> milliseconds."}
{"query": "The job-jar file on the remote FS is hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445144423722_0020/job.jar", "answer": "The job-jar file on the remote FS is hdfs://<*>"}
{"query": "The job-jar file on the remote FS is hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445144423722_0020/job.jar", "answer": "The job-jar file on the remote FS is hdfs://<*>"}
{"query": "The job-jar file on the remote FS is hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445144423722_0020/job.jar", "answer": "The job-jar file on the remote FS is hdfs://<*>"}
{"query": "job_1445144423722_0020Job Transitioned from INITED to SETUP", "answer": "job_<*>Job Transitioned from INITED to SETUP"}
{"query": "job_1445144423722_0020Job Transitioned from INITED to SETUP", "answer": "job_<*>Job Transitioned from INITED to SETUP"}
{"query": "job_1445144423722_0020Job Transitioned from INITED to SETUP", "answer": "job_<*>Job Transitioned from INITED to SETUP"}
{"query": "nodeBlacklistingEnabled:true", "answer": "nodeBlacklistingEnabled:true"}
{"query": "TaskAttempt: [attempt_1445144423722_0020_m_000005_0] using containerId: [container_1445144423722_0020_01_000007 on NM: [MSRA-SA-41.fareast.corp.microsoft.com:7109]", "answer": "TaskAttempt: [attempt_<*>] using containerId: [container_<*>_<*>_<*>_<*> on NM: [<*>:<*>]"}
{"query": "TaskAttempt: [attempt_1445144423722_0020_m_000000_0] using containerId: [container_1445144423722_0020_01_000002 on NM: [04DN8IQ.fareast.corp.microsoft.com:54883]", "answer": "TaskAttempt: [attempt_<*>] using containerId: [container_<*>_<*>_<*>_<*> on NM: [<*>:<*>]"}
{"query": "job_1445144423722_0020Job Transitioned from SETUP to RUNNING", "answer": "job_<*>Job Transitioned from SETUP to RUNNING"}
{"query": "job_1445144423722_0020Job Transitioned from SETUP to RUNNING", "answer": "job_<*>Job Transitioned from SETUP to RUNNING"}
{"query": "job_1445144423722_0020Job Transitioned from SETUP to RUNNING", "answer": "job_<*>Job Transitioned from SETUP to RUNNING"}
{"query": "job_1445144423722_0020Job Transitioned from SETUP to RUNNING", "answer": "job_<*>Job Transitioned from SETUP to RUNNING"}
{"query": "job_1445144423722_0020Job Transitioned from SETUP to RUNNING", "answer": "job_<*>Job Transitioned from SETUP to RUNNING"}
{"query": "Starting Socket Reader #1 for port 62270", "answer": "Starting Socket Reader #<*> for port <*>"}
{"query": "Starting Socket Reader #1 for port 62260", "answer": "Starting Socket Reader #<*> for port <*>"}
{"query": "Starting Socket Reader #1 for port 62260", "answer": "Starting Socket Reader #<*> for port <*>"}
{"query": "Starting Socket Reader #1 for port 62270", "answer": "Starting Socket Reader #<*> for port <*>"}
{"query": "Starting Socket Reader #1 for port 62260", "answer": "Starting Socket Reader #<*> for port <*>"}
{"query": "Starting Socket Reader #1 for port 62270", "answer": "Starting Socket Reader #<*> for port <*>"}
{"query": "DataStreamer Exception", "answer": "DataStreamer Exception"}
{"query": "DataStreamer Exception", "answer": "DataStreamer Exception"}
{"query": "DataStreamer Exception", "answer": "DataStreamer Exception"}
{"query": "DataStreamer Exception", "answer": "DataStreamer Exception"}
{"query": "Thread Thread[eventHandlingThread,5,main] threw an Exception.", "answer": "Thread Thread[eventHandlingThread,<*>,main] threw an Exception."}
{"query": "Thread Thread[eventHandlingThread,5,main] threw an Exception.", "answer": "Thread Thread[eventHandlingThread,<*>,main] threw an Exception."}
{"query": "Thread Thread[eventHandlingThread,5,main] threw an Exception.", "answer": "Thread Thread[eventHandlingThread,<*>,main] threw an Exception."}
{"query": "Thread Thread[eventHandlingThread,5,main] threw an Exception.", "answer": "Thread Thread[eventHandlingThread,<*>,main] threw an Exception."}
{"query": "Added attempt_1445144423722_0020_m_000002_1 to list of failed maps", "answer": "Added attempt_<*> to list of failed maps"}
{"query": "Added attempt_1445144423722_0020_m_000002_1 to list of failed maps", "answer": "Added attempt_<*> to list of failed maps"}
{"query": "Recalculating schedule, headroom=<memory:4096, vCores:-23>", "answer": "Recalculating schedule, headroom=<memory:<*>, vCores:<*>>"}
{"query": "Recalculating schedule, headroom=<memory:0, vCores:-27>", "answer": "Recalculating schedule, headroom=<memory:<*>, vCores:<*>>"}
{"query": "Recalculating schedule, headroom=<memory:0, vCores:-27>", "answer": "Recalculating schedule, headroom=<memory:<*>, vCores:<*>>"}
{"query": "Recalculating schedule, headroom=<memory:0, vCores:-27>", "answer": "Recalculating schedule, headroom=<memory:<*>, vCores:<*>>"}
{"query": "Connecting to ResourceManager at msra-sa-41/10.190.173.170:8030", "answer": "Connecting to ResourceManager at <*>/<*>:<*>"}
{"query": "Connecting to ResourceManager at msra-sa-41/10.190.173.170:8030", "answer": "Connecting to ResourceManager at <*>/<*>:<*>"}
{"query": "Connecting to ResourceManager at msra-sa-41/10.190.173.170:8030", "answer": "Connecting to ResourceManager at <*>/<*>:<*>"}
{"query": "Connecting to ResourceManager at msra-sa-41/10.190.173.170:8030", "answer": "Connecting to ResourceManager at <*>/<*>:<*>"}
{"query": "Auth successful for job_1445144423722_0020 (auth:SIMPLE)", "answer": "Auth successful for job_<*> (auth:SIMPLE)"}
{"query": "Auth successful for job_1445144423722_0020 (auth:SIMPLE)", "answer": "Auth successful for job_<*> (auth:SIMPLE)"}
{"query": "Auth successful for job_1445144423722_0020 (auth:SIMPLE)", "answer": "Auth successful for job_<*> (auth:SIMPLE)"}
{"query": "Auth successful for job_1445144423722_0020 (auth:SIMPLE)", "answer": "Auth successful for job_<*> (auth:SIMPLE)"}
{"query": "Auth successful for job_1445144423722_0020 (auth:SIMPLE)", "answer": "Auth successful for job_<*> (auth:SIMPLE)"}
{"query": "getResources() for application_1445144423722_0020: ask=0 release= 1 newContainers=0 finishedContainers=1 resourcelimit=<memory:1024, vCores:-26> knownNMs=4", "answer": "getResources() for application_<*>: ask=<*> release= <*> newContainers=<*> finishedContainers=<*> resourcelimit=<memory:<*>, vCores:<*>> knownNMs=<*>"}
{"query": "Cannot assign container Container: [ContainerId: container_1445144423722_0020_01_000012, NodeId: MSRA-SA-39.fareast.corp.microsoft.com:28345, NodeHttpAddress: MSRA-SA-39.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 172.22.149.145:28345 }, ] for a map as either  container memory less than required <memory:1024, vCores:1> or no pending map tasks - maps.isEmpty=true", "answer": "Cannot assign container Container: [ContainerId: container_<*>, NodeId: <*>:<*>, NodeHttpAddress: <*>:<*>, Resource: <memory:<*>, vCores:<*>>, Priority: <*>, Token: Token { kind: ContainerToken, service: <*>:<*> }, ] for a map as either  container memory less than required <memory:<*>, vCores:<*>> or no pending map tasks - maps.isEmpty=true"}
{"query": "Reduce slow start threshold reached. Scheduling reduces.", "answer": "Reduce slow start threshold reached. Scheduling reduces."}
{"query": "Reduce slow start threshold reached. Scheduling reduces.", "answer": "Reduce slow start threshold reached. Scheduling reduces."}
{"query": "Reduce slow start threshold reached. Scheduling reduces.", "answer": "Reduce slow start threshold reached. Scheduling reduces."}
{"query": "ERROR IN CONTACTING RM.", "answer": "ERROR IN CONTACTING RM."}
{"query": "ERROR IN CONTACTING RM.", "answer": "ERROR IN CONTACTING RM."}
{"query": "ERROR IN CONTACTING RM.", "answer": "ERROR IN CONTACTING RM."}
{"query": "Event Writer setup for JobId: job_1445144423722_0020, File: hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445144423722_0020/job_1445144423722_0020_1.jhist", "answer": "Event Writer setup for JobId: job_<*>, File: hdfs://<*>"}
{"query": "Event Writer setup for JobId: job_1445144423722_0020, File: hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445144423722_0020/job_1445144423722_0020_1.jhist", "answer": "Event Writer setup for JobId: job_<*>, File: hdfs://<*>"}
{"query": "MRAppMaster launching normal, non-uberized, multi-container job job_1445144423722_0020.", "answer": "MRAppMaster launching normal, non-uberized, multi-container job job_<*>."}
{"query": "MRAppMaster launching normal, non-uberized, multi-container job job_1445144423722_0020.", "answer": "MRAppMaster launching normal, non-uberized, multi-container job job_<*>."}
{"query": "Jetty bound to port 62267", "answer": "Jetty bound to port <*>"}
{"query": "Jetty bound to port 62267", "answer": "Jetty bound to port <*>"}
{"query": "Jetty bound to port 62267", "answer": "Jetty bound to port <*>"}
{"query": "Jetty bound to port 62267", "answer": "Jetty bound to port <*>"}
{"query": "Jetty bound to port 62267", "answer": "Jetty bound to port <*>"}
{"query": "loaded properties from hadoop-metrics2.properties", "answer": "loaded properties from hadoop-metrics2.properties"}
{"query": "loaded properties from hadoop-metrics2.properties", "answer": "loaded properties from hadoop-metrics2.properties"}
{"query": "loaded properties from hadoop-metrics2.properties", "answer": "loaded properties from hadoop-metrics2.properties"}
{"query": "loaded properties from hadoop-metrics2.properties", "answer": "loaded properties from hadoop-metrics2.properties"}
{"query": "loaded properties from hadoop-metrics2.properties", "answer": "loaded properties from hadoop-metrics2.properties"}
{"query": "loaded properties from hadoop-metrics2.properties", "answer": "loaded properties from hadoop-metrics2.properties"}
{"query": "DFSOutputStream ResponseProcessor exception  for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743512_2731", "answer": "DFSOutputStream ResponseProcessor exception  for block BP-<*>:blk_<*>"}
{"query": "Putting shuffle token in serviceData", "answer": "Putting shuffle token in serviceData"}
{"query": "Putting shuffle token in serviceData", "answer": "Putting shuffle token in serviceData"}
{"query": "Putting shuffle token in serviceData", "answer": "Putting shuffle token in serviceData"}
{"query": "Input size for job job_1445144423722_0020 = 1256521728. Number of splits = 10", "answer": "Input size for job job_<*> = <*>. Number of splits = <*>"}
{"query": "Input size for job job_1445144423722_0020 = 1256521728. Number of splits = 10", "answer": "Input size for job job_<*> = <*>. Number of splits = <*>"}
{"query": "Input size for job job_1445144423722_0020 = 1256521728. Number of splits = 10", "answer": "Input size for job job_<*> = <*>. Number of splits = <*>"}
{"query": "Input size for job job_1445144423722_0020 = 1256521728. Number of splits = 10", "answer": "Input size for job job_<*> = <*>. Number of splits = <*>"}
{"query": "Number of reduces for job job_1445144423722_0020 = 1", "answer": "Number of reduces for job job_<*> = <*>"}
{"query": "Number of reduces for job job_1445144423722_0020 = 1", "answer": "Number of reduces for job job_<*> = <*>"}
{"query": "Number of reduces for job job_1445144423722_0020 = 1", "answer": "Number of reduces for job job_<*> = <*>"}
{"query": "Instantiated MRClientService at MININT-FNANLI5.fareast.corp.microsoft.com/10.86.169.121:62260", "answer": "Instantiated MRClientService at MININT-<*>/<*>:<*>"}
{"query": "Instantiated MRClientService at MININT-FNANLI5.fareast.corp.microsoft.com/10.86.169.121:62260", "answer": "Instantiated MRClientService at MININT-<*>/<*>:<*>"}
{"query": "Instantiated MRClientService at MININT-FNANLI5.fareast.corp.microsoft.com/10.86.169.121:62260", "answer": "Instantiated MRClientService at MININT-<*>/<*>:<*>"}
{"query": "Registered webapp guice modules", "answer": "Registered webapp guice modules"}
{"query": "Registered webapp guice modules", "answer": "Registered webapp guice modules"}
{"query": "OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter", "answer": "OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter"}
{"query": "OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter", "answer": "OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter"}
{"query": "OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter", "answer": "OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter"}
{"query": "OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter", "answer": "OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter"}
{"query": "OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter", "answer": "OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter"}
{"query": "Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 20 cluster_timestamp: 1445144423722 } attemptId: 1 } keyId: -127633188)", "answer": "Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>)"}
{"query": "Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 20 cluster_timestamp: 1445144423722 } attemptId: 1 } keyId: -127633188)", "answer": "Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>)"}
{"query": "Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 20 cluster_timestamp: 1445144423722 } attemptId: 1 } keyId: -127633188)", "answer": "Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>)"}
{"query": "Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 20 cluster_timestamp: 1445144423722 } attemptId: 1 } keyId: -127633188)", "answer": "Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>)"}
{"query": "Received completed container container_1445144423722_0020_01_000005", "answer": "Received completed container container_<*>"}
{"query": "Received completed container container_1445144423722_0020_01_000012", "answer": "Received completed container container_<*>"}
{"query": "Received completed container container_1445144423722_0020_01_000012", "answer": "Received completed container container_<*>"}
{"query": "Shuffle port returned by ContainerManager for attempt_1445144423722_0020_m_000009_0 : 13562", "answer": "Shuffle port returned by ContainerManager for attempt_<*> : <*>"}
{"query": "Shuffle port returned by ContainerManager for attempt_1445144423722_0020_m_000002_0 : 13562", "answer": "Shuffle port returned by ContainerManager for attempt_<*> : <*>"}
{"query": "Slow ReadProcessor read fields took 65020ms (threshold=30000ms); ack: seqno: -2 status: SUCCESS status: ERROR downstreamAckTimeNanos: 0, targets: [10.86.169.121:50010, 10.190.173.170:50010]", "answer": "Slow ReadProcessor read fields took <*>ms (threshold=<*>ms); ack: seqno: <*> status: SUCCESS status: ERROR downstreamAckTimeNanos: <*>, targets: [<*>:<*>, <*>:<*>]"}
{"query": "Slow ReadProcessor read fields took 65020ms (threshold=30000ms); ack: seqno: -2 status: SUCCESS status: ERROR downstreamAckTimeNanos: 0, targets: [10.86.169.121:50010, 10.190.173.170:50010]", "answer": "Slow ReadProcessor read fields took <*>ms (threshold=<*>ms); ack: seqno: <*> status: SUCCESS status: ERROR downstreamAckTimeNanos: <*>, targets: [<*>:<*>, <*>:<*>]"}
{"query": "Slow ReadProcessor read fields took 65020ms (threshold=30000ms); ack: seqno: -2 status: SUCCESS status: ERROR downstreamAckTimeNanos: 0, targets: [10.86.169.121:50010, 10.190.173.170:50010]", "answer": "Slow ReadProcessor read fields took <*>ms (threshold=<*>ms); ack: seqno: <*> status: SUCCESS status: ERROR downstreamAckTimeNanos: <*>, targets: [<*>:<*>, <*>:<*>]"}
{"query": "Slow ReadProcessor read fields took 65020ms (threshold=30000ms); ack: seqno: -2 status: SUCCESS status: ERROR downstreamAckTimeNanos: 0, targets: [10.86.169.121:50010, 10.190.173.170:50010]", "answer": "Slow ReadProcessor read fields took <*>ms (threshold=<*>ms); ack: seqno: <*> status: SUCCESS status: ERROR downstreamAckTimeNanos: <*>, targets: [<*>:<*>, <*>:<*>]"}
{"query": "job_1445144423722_0020Job Transitioned from NEW to INITED", "answer": "job_<*>Job Transitioned from NEW to INITED"}
{"query": "attempt_1445144423722_0020_m_000005_0 TaskAttempt Transitioned from ASSIGNED to RUNNING", "answer": "attempt_<*> TaskAttempt Transitioned from ASSIGNED to RUNNING"}
{"query": "Task cleanup failed for attempt attempt_1445144423722_0020_m_000002_0", "answer": "Task cleanup failed for attempt attempt_<*>"}
{"query": "Task cleanup failed for attempt attempt_1445144423722_0020_m_000002_0", "answer": "Task cleanup failed for attempt attempt_<*>"}
{"query": "Task cleanup failed for attempt attempt_1445144423722_0020_m_000001_0", "answer": "Task cleanup failed for attempt attempt_<*>"}
{"query": "Task cleanup failed for attempt attempt_1445144423722_0020_m_000001_0", "answer": "Task cleanup failed for attempt attempt_<*>"}
{"query": "Task cleanup failed for attempt attempt_1445144423722_0020_m_000002_0", "answer": "Task cleanup failed for attempt attempt_<*>"}
{"query": "JVM with ID: jvm_1445144423722_0020_m_000004 given task: attempt_1445144423722_0020_m_000002_0", "answer": "JVM with ID: jvm_<*> given task: <*>_<*>"}
{"query": "JVM with ID: jvm_1445144423722_0020_m_000007 given task: attempt_1445144423722_0020_m_000005_0", "answer": "JVM with ID: jvm_<*> given task: <*>_<*>"}
{"query": "JVM with ID: jvm_1445144423722_0020_m_000003 given task: attempt_1445144423722_0020_m_000001_0", "answer": "JVM with ID: jvm_<*> given task: <*>_<*>"}
{"query": "JVM with ID: jvm_1445144423722_0020_m_000006 given task: attempt_1445144423722_0020_m_000004_0", "answer": "JVM with ID: jvm_<*> given task: <*>_<*>"}
{"query": "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.079464614", "answer": "Progress of TaskAttempt attempt_<*> is : <*>.<*>"}
{"query": "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.667", "answer": "Progress of TaskAttempt attempt_<*> is : <*>.<*>"}
{"query": "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.19211523", "answer": "Progress of TaskAttempt attempt_<*> is : <*>.<*>"}
{"query": "Progress of TaskAttempt attempt_1445144423722_0020_m_000000_0 is : 0.1430594", "answer": "Progress of TaskAttempt attempt_<*> is : <*>.<*>"}
{"query": "Processing the event EventType: TASK_ABORT", "answer": "Processing the event EventType: TASK_ABORT"}
{"query": "Processing the event EventType: TASK_ABORT", "answer": "Processing the event EventType: TASK_ABORT"}
{"query": "Processing the event EventType: TASK_ABORT", "answer": "Processing the event EventType: TASK_ABORT"}
{"query": "Processing the event EventType: TASK_ABORT", "answer": "Processing the event EventType: TASK_ABORT"}
{"query": "Processing the event EventType: TASK_ABORT", "answer": "Processing the event EventType: TASK_ABORT"}
{"query": "Created MRAppMaster for application appattempt_1445144423722_0020_000001", "answer": "Created MRAppMaster for application appattempt_<*>"}
{"query": "Created MRAppMaster for application appattempt_1445144423722_0020_000001", "answer": "Created MRAppMaster for application appattempt_<*>"}
{"query": "Created MRAppMaster for application appattempt_1445144423722_0020_000001", "answer": "Created MRAppMaster for application appattempt_<*>"}
{"query": "Using callQueue class java.util.concurrent.LinkedBlockingQueue", "answer": "Using callQueue class java.util.concurrent.LinkedBlockingQueue"}
{"query": "Using callQueue class java.util.concurrent.LinkedBlockingQueue", "answer": "Using callQueue class java.util.concurrent.LinkedBlockingQueue"}
{"query": "Using callQueue class java.util.concurrent.LinkedBlockingQueue", "answer": "Using callQueue class java.util.concurrent.LinkedBlockingQueue"}
{"query": "Using callQueue class java.util.concurrent.LinkedBlockingQueue", "answer": "Using callQueue class java.util.concurrent.LinkedBlockingQueue"}
{"query": "Scheduling a redundant attempt for task task_1445144423722_0020_m_000000", "answer": "Scheduling a redundant attempt for task task_<*>"}
{"query": "Scheduling a redundant attempt for task task_1445144423722_0020_m_000000", "answer": "Scheduling a redundant attempt for task task_<*>"}
{"query": "Scheduling a redundant attempt for task task_1445144423722_0020_m_000000", "answer": "Scheduling a redundant attempt for task task_<*>"}
{"query": "Scheduling a redundant attempt for task task_1445144423722_0020_m_000000", "answer": "Scheduling a redundant attempt for task task_<*>"}
{"query": "Retrying connect to server: msra-sa-41:8030. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)", "answer": "Retrying connect to server: <*>:<*>. Already tried <*> time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=<*>, sleepTime=<*> MILLISECONDS)"}
{"query": "Retrying connect to server: msra-sa-41:8030. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)", "answer": "Retrying connect to server: <*>:<*>. Already tried <*> time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=<*>, sleepTime=<*> MILLISECONDS)"}
{"query": "2 failures on node MININT-FNANLI5.fareast.corp.microsoft.com", "answer": "<*> failures on node MININT-<*>"}
{"query": "1 failures on node MININT-FNANLI5.fareast.corp.microsoft.com", "answer": "<*> failures on node MININT-<*>"}
{"query": "2 failures on node MININT-FNANLI5.fareast.corp.microsoft.com", "answer": "<*> failures on node MININT-<*>"}
{"query": "2 failures on node MININT-FNANLI5.fareast.corp.microsoft.com", "answer": "<*> failures on node MININT-<*>"}
{"query": "Opening proxy : MININT-FNANLI5.fareast.corp.microsoft.com:52368", "answer": "Opening proxy : <*>:<*>"}
{"query": "Opening proxy : MSRA-SA-41.fareast.corp.microsoft.com:7109", "answer": "Opening proxy : <*>:<*>"}
{"query": "Opening proxy : 04DN8IQ.fareast.corp.microsoft.com:54883", "answer": "Opening proxy : <*>:<*>"}
{"query": "Opening proxy : 04DN8IQ.fareast.corp.microsoft.com:54883", "answer": "Opening proxy : <*>:<*>"}
{"query": "blacklistDisablePercent is 33", "answer": "blacklistDisablePercent is <*>"}
{"query": "blacklistDisablePercent is 33", "answer": "blacklistDisablePercent is <*>"}
{"query": "blacklistDisablePercent is 33", "answer": "blacklistDisablePercent is <*>"}
{"query": "Size of containertokens_dob is 1", "answer": "Size of containertokens_dob is <*>"}
{"query": "Size of containertokens_dob is 1", "answer": "Size of containertokens_dob is <*>"}
{"query": "Size of containertokens_dob is 1", "answer": "Size of containertokens_dob is <*>"}
{"query": "Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce", "answer": "Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce"}
{"query": "Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static", "answer": "Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static"}
{"query": "Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)", "answer": "Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)"}
{"query": "MRAppMaster metrics system started", "answer": "MRAppMaster metrics system started"}
{"query": "MRAppMaster metrics system started", "answer": "MRAppMaster metrics system started"}
{"query": "MRAppMaster metrics system started", "answer": "MRAppMaster metrics system started"}
{"query": "MRAppMaster metrics system started", "answer": "MRAppMaster metrics system started"}
{"query": "Task succeeded with attempt attempt_1445144423722_0020_m_000003_0", "answer": "Task succeeded with attempt attempt_<*>"}
{"query": "Task succeeded with attempt attempt_1445144423722_0020_m_000003_0", "answer": "Task succeeded with attempt attempt_<*>"}
{"query": "Task succeeded with attempt attempt_1445144423722_0020_m_000003_0", "answer": "Task succeeded with attempt attempt_<*>"}
{"query": "Task succeeded with attempt attempt_1445144423722_0020_m_000003_0", "answer": "Task succeeded with attempt attempt_<*>"}
{"query": "Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server", "answer": "Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server"}
{"query": "IPC Server Responder: starting", "answer": "IPC Server Responder: starting"}
{"query": "IPC Server listener on 62260: starting", "answer": "IPC Server listener on <*>: starting"}
{"query": "IPC Server Responder: starting", "answer": "IPC Server Responder: starting"}
{"query": "IPC Server listener on 62260: starting", "answer": "IPC Server listener on <*>: starting"}
{"query": "IPC Server listener on 62260: starting", "answer": "IPC Server listener on <*>: starting"}
{"query": "After Scheduling: PendingReds:1 ScheduledMaps:7 ScheduledReds:0 AssignedMaps:3 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:3 ContRel:0 HostLocal:0 RackLocal:3", "answer": "After Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:0 ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>"}
{"query": "Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent@7317849d", "answer": "Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent@<*>"}
{"query": "Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent@7317849d", "answer": "Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent@<*>"}
{"query": "Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent@7317849d", "answer": "Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent@<*>"}
{"query": "Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent@7317849d", "answer": "Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent@<*>"}
{"query": "Emitting job history data to the timeline server is not enabled", "answer": "Emitting job history data to the timeline server is not enabled"}
{"query": "Emitting job history data to the timeline server is not enabled", "answer": "Emitting job history data to the timeline server is not enabled"}
{"query": "Emitting job history data to the timeline server is not enabled", "answer": "Emitting job history data to the timeline server is not enabled"}
{"query": "Emitting job history data to the timeline server is not enabled", "answer": "Emitting job history data to the timeline server is not enabled"}
{"query": "Emitting job history data to the timeline server is not enabled", "answer": "Emitting job history data to the timeline server is not enabled"}
{"query": "Http request log for http.requests.mapreduce is not defined", "answer": "Http request log for http.requests.mapreduce is not defined"}
{"query": "Http request log for http.requests.mapreduce is not defined", "answer": "Http request log for http.requests.mapreduce is not defined"}
{"query": "Http request log for http.requests.mapreduce is not defined", "answer": "Http request log for http.requests.mapreduce is not defined"}
{"query": "Http request log for http.requests.mapreduce is not defined", "answer": "Http request log for http.requests.mapreduce is not defined"}
{"query": "Http request log for http.requests.mapreduce is not defined", "answer": "Http request log for http.requests.mapreduce is not defined"}
{"query": "Adding job token for job_1445144423722_0020 to jobTokenSecretManager", "answer": "Adding job token for job_<*> to jobTokenSecretManager"}
{"query": "Adding job token for job_1445144423722_0020 to jobTokenSecretManager", "answer": "Adding job token for job_<*> to jobTokenSecretManager"}
{"query": "Diagnostics report from attempt_1445144423722_0020_m_000002_0: Error: java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost", "answer": "Diagnostics report from attempt_<*>: Error: java.net.NoRouteToHostException: No Route to Host from  MININT-<*>/<*> to <*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost"}
{"query": "maxTaskFailuresPerNode is 3", "answer": "maxTaskFailuresPerNode is <*>"}
{"query": "maxTaskFailuresPerNode is 3", "answer": "maxTaskFailuresPerNode is <*>"}
{"query": "Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1445144423722_0020_01_000008 taskAttempt attempt_1445144423722_0020_m_000006_0", "answer": "Processing the event EventType: CONTAINER_REMOTE_<*> for container container_<*> taskAttempt attempt_<*>"}
{"query": "Container complete event for unknown container id container_1445144423722_0020_01_000012", "answer": "Container complete event for unknown container id container_<*>"}
{"query": "Container complete event for unknown container id container_1445144423722_0020_01_000012", "answer": "Container complete event for unknown container id container_<*>"}
{"query": "Container complete event for unknown container id container_1445144423722_0020_01_000012", "answer": "Container complete event for unknown container id container_<*>"}
{"query": "All maps assigned. Ramping up all remaining reduces:1", "answer": "All maps assigned. Ramping up all remaining reduces:<*>"}
{"query": "All maps assigned. Ramping up all remaining reduces:1", "answer": "All maps assigned. Ramping up all remaining reduces:<*>"}
{"query": "All maps assigned. Ramping up all remaining reduces:1", "answer": "All maps assigned. Ramping up all remaining reduces:<*>"}
{"query": "All maps assigned. Ramping up all remaining reduces:1", "answer": "All maps assigned. Ramping up all remaining reduces:<*>"}
{"query": "Using mapred newApiCommitter.", "answer": "Using mapred newApiCommitter."}
{"query": "Using mapred newApiCommitter.", "answer": "Using mapred newApiCommitter."}
{"query": "Using mapred newApiCommitter.", "answer": "Using mapred newApiCommitter."}
{"query": "Using mapred newApiCommitter.", "answer": "Using mapred newApiCommitter."}
{"query": "reduceResourceRequest:<memory:1024, vCores:1>", "answer": "reduceResourceRequest:<memory:<*>, vCores:<*>>"}
{"query": "reduceResourceRequest:<memory:1024, vCores:1>", "answer": "reduceResourceRequest:<memory:<*>, vCores:<*>>"}
{"query": "reduceResourceRequest:<memory:1024, vCores:1>", "answer": "reduceResourceRequest:<memory:<*>, vCores:<*>>"}
{"query": "DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_1445144423722_0020_m_000000", "answer": "DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_<*>"}
{"query": "DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_1445144423722_0020_m_000000", "answer": "DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_<*>"}
{"query": "DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_1445144423722_0020_m_000000", "answer": "DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_<*>"}
{"query": "Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog", "answer": "Logging to <*>(org.mortbay.log) via <*>"}
{"query": "Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog", "answer": "Logging to <*>(org.mortbay.log) via <*>"}
{"query": "Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog", "answer": "Logging to <*>(org.mortbay.log) via <*>"}
{"query": "Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog", "answer": "Logging to <*>(org.mortbay.log) via <*>"}
{"query": "Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog", "answer": "Logging to <*>(org.mortbay.log) via <*>"}
{"query": "Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog", "answer": "Logging to <*>(org.mortbay.log) via <*>"}
{"query": "maxContainerCapability: <memory:8192, vCores:32>", "answer": "maxContainerCapability: <memory:<*>, vCores:<*>>"}
{"query": "maxContainerCapability: <memory:8192, vCores:32>", "answer": "maxContainerCapability: <memory:<*>, vCores:<*>>"}
{"query": "maxContainerCapability: <memory:8192, vCores:32>", "answer": "maxContainerCapability: <memory:<*>, vCores:<*>>"}
{"query": "maxContainerCapability: <memory:8192, vCores:32>", "answer": "maxContainerCapability: <memory:<*>, vCores:<*>>"}
{"query": "maxContainerCapability: <memory:8192, vCores:32>", "answer": "maxContainerCapability: <memory:<*>, vCores:<*>>"}
{"query": "maxContainerCapability: <memory:8192, vCores:32>", "answer": "maxContainerCapability: <memory:<*>, vCores:<*>>"}
{"query": "OutputCommitter set in config null", "answer": "OutputCommitter set in config null"}
{"query": "OutputCommitter set in config null", "answer": "OutputCommitter set in config null"}
{"query": "OutputCommitter set in config null", "answer": "OutputCommitter set in config null"}
{"query": "OutputCommitter set in config null", "answer": "OutputCommitter set in config null"}
{"query": "Executing with tokens:", "answer": "Executing with tokens:"}
{"query": "Executing with tokens:", "answer": "Executing with tokens:"}
{"query": "Executing with tokens:", "answer": "Executing with tokens:"}
{"query": "Executing with tokens:", "answer": "Executing with tokens:"}
{"query": "Executing with tokens:", "answer": "Executing with tokens:"}
{"query": "Reduce slow start threshold not met. completedMapsForReduceSlowstart 1", "answer": "Reduce slow start threshold not met. completedMapsForReduceSlowstart <*>"}
{"query": "Reduce slow start threshold not met. completedMapsForReduceSlowstart 1", "answer": "Reduce slow start threshold not met. completedMapsForReduceSlowstart <*>"}
{"query": "Done acknowledgement from attempt_1445144423722_0020_m_000003_0", "answer": "Done acknowledgement from attempt_<*>"}
{"query": "Done acknowledgement from attempt_1445144423722_0020_m_000003_0", "answer": "Done acknowledgement from attempt_<*>"}
{"query": "Done acknowledgement from attempt_1445144423722_0020_m_000003_0", "answer": "Done acknowledgement from attempt_<*>"}
{"query": "Scheduled snapshot period at 10 second(s).", "answer": "Scheduled snapshot period at <*> second(s)."}
{"query": "Scheduled snapshot period at 10 second(s).", "answer": "Scheduled snapshot period at <*> second(s)."}
{"query": "Error Recovery for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743512_2731 in pipeline 10.86.169.121:50010, 10.190.173.170:50010: bad datanode 10.190.173.170:50010", "answer": "Error Recovery for block BP-<*>:blk_<*> in pipeline <*>:<*>, <*>:<*>: bad datanode <*>:<*>"}
{"query": "Error Recovery for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743512_2731 in pipeline 10.86.169.121:50010, 10.190.173.170:50010: bad datanode 10.190.173.170:50010", "answer": "Error Recovery for block BP-<*>:blk_<*> in pipeline <*>:<*>, <*>:<*>: bad datanode <*>:<*>"}
{"query": "Error Recovery for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743512_2731 in pipeline 10.86.169.121:50010, 10.190.173.170:50010: bad datanode 10.190.173.170:50010", "answer": "Error Recovery for block BP-<*>:blk_<*> in pipeline <*>:<*>, <*>:<*>: bad datanode <*>:<*>"}
{"query": "Upper limit on the thread pool size is 500", "answer": "Upper limit on the thread pool size is <*>"}
{"query": "Upper limit on the thread pool size is 500", "answer": "Upper limit on the thread pool size is <*>"}
{"query": "Upper limit on the thread pool size is 500", "answer": "Upper limit on the thread pool size is <*>"}
{"query": "Not uberizing job_1445144423722_0020 because: not enabled; too many maps; too much input;", "answer": "Not uberizing job_<*> because: not enabled; too many maps; too much input;"}
{"query": "Not uberizing job_1445144423722_0020 because: not enabled; too many maps; too much input;", "answer": "Not uberizing job_<*> because: not enabled; too many maps; too much input;"}
{"query": "Got allocated containers 1", "answer": "Got allocated containers <*>"}
{"query": "Got allocated containers 1", "answer": "Got allocated containers <*>"}
{"query": "Got allocated containers 1", "answer": "Got allocated containers <*>"}
{"query": "JVM with ID : jvm_1445144423722_0020_m_000007 asked for a task", "answer": "JVM with ID : jvm_<*> asked for a task"}
{"query": "Extract jar:file:/D:/hadoop-2.6.0-localbox/share/hadoop/yarn/hadoop-yarn-common-2.6.0-SNAPSHOT.jar!/webapps/mapreduce to C:\\Users\\msrabi\\AppData\\Local\\Temp\\Jetty_0_0_0_0_62267_mapreduce____.8n7xum\\webapp", "answer": "Extract jar:file:<*> to <*>"}
{"query": "Extract jar:file:/D:/hadoop-2.6.0-localbox/share/hadoop/yarn/hadoop-yarn-common-2.6.0-SNAPSHOT.jar!/webapps/mapreduce to C:\\Users\\msrabi\\AppData\\Local\\Temp\\Jetty_0_0_0_0_62267_mapreduce____.8n7xum\\webapp", "answer": "Extract jar:file:<*> to <*>"}
{"query": "Extract jar:file:/D:/hadoop-2.6.0-localbox/share/hadoop/yarn/hadoop-yarn-common-2.6.0-SNAPSHOT.jar!/webapps/mapreduce to C:\\Users\\msrabi\\AppData\\Local\\Temp\\Jetty_0_0_0_0_62267_mapreduce____.8n7xum\\webapp", "answer": "Extract jar:file:<*> to <*>"}
{"query": "Task: attempt_1445144423722_0020_m_000002_0 - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost", "answer": "Task: attempt_<*> - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-<*>/<*> to <*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost"}
{"query": "Task: attempt_1445144423722_0020_m_000002_0 - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost", "answer": "Task: attempt_<*> - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-<*>/<*> to <*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost"}
{"query": "Task: attempt_1445144423722_0020_m_000002_0 - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost", "answer": "Task: attempt_<*> - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-<*>/<*> to <*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost"}
{"query": "Task: attempt_1445144423722_0020_m_000002_0 - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost", "answer": "Task: attempt_<*> - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-<*>/<*> to <*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost"}
{"query": "Task: attempt_1445144423722_0020_m_000002_0 - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost", "answer": "Task: attempt_<*> - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-<*>/<*> to <*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost"}
{"query": "Task: attempt_1445144423722_0020_m_000001_0 - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost", "answer": "Task: attempt_<*> - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-<*>/<*> to <*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost"}
{"query": "Task: attempt_1445144423722_0020_m_000001_0 - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost", "answer": "Task: attempt_<*> - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-<*>/<*> to <*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost"}
{"query": "queue: default", "answer": "queue: default"}
{"query": "queue: default", "answer": "queue: default"}
{"query": "queue: default", "answer": "queue: default"}
{"query": "queue: default", "answer": "queue: default"}
{"query": "Diagnostics report from attempt_1445144423722_0020_m_000003_0: Container killed by the ApplicationMaster.", "answer": "Diagnostics report from attempt_<*>: Container killed by the ApplicationMaster."}
{"query": "Diagnostics report from attempt_1445144423722_0020_m_000003_0: Container killed by the ApplicationMaster.", "answer": "Diagnostics report from attempt_<*>: Container killed by the ApplicationMaster."}
{"query": "Diagnostics report from attempt_1445144423722_0020_m_000003_0: Container killed by the ApplicationMaster.", "answer": "Diagnostics report from attempt_<*>: Container killed by the ApplicationMaster."}
{"query": "Adding #0 tokens and #1 secret keys for NM use for launching container", "answer": "Adding #<*> tokens and #<*> secret keys for NM use for launching container"}
{"query": "Adding #0 tokens and #1 secret keys for NM use for launching container", "answer": "Adding #<*> tokens and #<*> secret keys for NM use for launching container"}
{"query": "Adding #0 tokens and #1 secret keys for NM use for launching container", "answer": "Adding #<*> tokens and #<*> secret keys for NM use for launching container"}
{"query": "Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000", "answer": "Address change detected. Old: <*>/<*>:<*> New: <*>:<*>"}
{"query": "Resolved MSRA-SA-39.fareast.corp.microsoft.com to /default-rack", "answer": "Resolved <*> to /default-rack"}
{"query": "Default file system [hdfs://msra-sa-41:9000]", "answer": "Default file system [hdfs://<*>:<*>]"}
{"query": "Default file system [hdfs://msra-sa-41:9000]", "answer": "Default file system [hdfs://<*>:<*>]"}
{"query": "Default file system [hdfs://msra-sa-41:9000]", "answer": "Default file system [hdfs://<*>:<*>]"}
{"query": "Default file system [hdfs://msra-sa-41:9000]", "answer": "Default file system [hdfs://<*>:<*>]"}
{"query": "Default file system [hdfs://msra-sa-41:9000]", "answer": "Default file system [hdfs://<*>:<*>]"}
{"query": "Default file system [hdfs://msra-sa-41:9000]", "answer": "Default file system [hdfs://<*>:<*>]"}
{"query": "Default file system [hdfs://msra-sa-41:9000]", "answer": "Default file system [hdfs://<*>:<*>]"}
{"query": "Default file system [hdfs://msra-sa-41:9000]", "answer": "Default file system [hdfs://<*>:<*>]"}
{"query": "The job-conf file on the remote FS is /tmp/hadoop-yarn/staging/msrabi/.staging/job_1445144423722_0020/job.xml", "answer": "The job-conf file on the remote FS is <*>"}
{"query": "The job-conf file on the remote FS is /tmp/hadoop-yarn/staging/msrabi/.staging/job_1445144423722_0020/job.xml", "answer": "The job-conf file on the remote FS is <*>"}
{"query": "The job-conf file on the remote FS is /tmp/hadoop-yarn/staging/msrabi/.staging/job_1445144423722_0020/job.xml", "answer": "The job-conf file on the remote FS is <*>"}
{"query": "The job-conf file on the remote FS is /tmp/hadoop-yarn/staging/msrabi/.staging/job_1445144423722_0020/job.xml", "answer": "The job-conf file on the remote FS is <*>"}
{"query": "Assigned container container_1445144423722_0020_01_000011 to attempt_1445144423722_0020_m_000009_0", "answer": "Assigned container container_<*> to attempt_<*>"}
{"query": "Assigned container container_1445144423722_0020_01_000002 to attempt_1445144423722_0020_m_000000_0", "answer": "Assigned container container_<*> to attempt_<*>"}
{"query": "Assigned container container_1445144423722_0020_01_000006 to attempt_1445144423722_0020_m_000004_0", "answer": "Assigned container container_<*> to attempt_<*>"}
{"query": "task_1445144423722_0020_m_000005 Task Transitioned from NEW to SCHEDULED", "answer": "task_<*> Task Transitioned from NEW to SCHEDULED"}
{"query": "Web app /mapreduce started at 62267", "answer": "Web app /mapreduce started at <*>"}
{"query": "Web app /mapreduce started at 62267", "answer": "Web app /mapreduce started at <*>"}
{"query": "Web app /mapreduce started at 62267", "answer": "Web app /mapreduce started at <*>"}
{"query": "Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher", "answer": "Registering class org.apache.hadoop.mapreduce.<*> for class org.apache.hadoop.mapreduce.<*>"}
{"query": "Registering class org.apache.hadoop.mapreduce.v2.app.speculate.Speculator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$SpeculatorEventDispatcher", "answer": "Registering class org.apache.hadoop.mapreduce.<*> for class org.apache.hadoop.mapreduce.<*>"}
{"query": "Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher", "answer": "Registering class org.apache.hadoop.mapreduce.<*> for class org.apache.hadoop.mapreduce.<*>"}
{"query": "Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler", "answer": "Registering class org.apache.hadoop.mapreduce.<*> for class org.apache.hadoop.mapreduce.<*>"}
{"query": "adding path spec: /mapreduce/*", "answer": "adding path spec: /<*>/*"}
{"query": "adding path spec: /mapreduce/*", "answer": "adding path spec: /<*>/*"}
{"query": "adding path spec: /mapreduce/*", "answer": "adding path spec: /<*>/*"}
